{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    }
   ],
   "source": [
    "]activate .; instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level language modelling\n",
    "Based on [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, chunk, batchseq, throttle, crossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load text data from `input.txt` and split it into characters, then turn it into the numeric form needed by the model.\n",
    "\n",
    "The model will take a sequence of characters, like \"the do\", and try to produce the next character (e.g. 't' or 'g' would be likely here but not 'd'). The target output sequence $Y$ is therefore just the input sequence $X$ offset by one, e.g.\n",
    "\n",
    "* $X$: `the dog`\n",
    "* $Y$: `he dog_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = collect(String(read(\"data/input.txt\")))\n",
    "alphabet = [unique(text)..., '_']\n",
    "text = map(ch -> onehot(ch, alphabet), text)\n",
    "stop = onehot('_', alphabet)\n",
    "\n",
    "N = length(alphabet)\n",
    "seqlen = 50\n",
    "nbatch = 50\n",
    "\n",
    "Xs = collect(partition(batchseq(chunk(text, nbatch), stop), seqlen))\n",
    "Ys = collect(partition(batchseq(chunk(text[2:end], nbatch), stop), seqlen));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will be a multi-layer LSTM, which takes a single character as input and produces a single character as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  LSTM(N, 128),\n",
    "  LSTM(128, 128),\n",
    "  Dense(128, N),\n",
    "  softmax)\n",
    "\n",
    "m = gpu(m)\n",
    "\n",
    "predict(x) = m(gpu(collect(x)))\n",
    "\n",
    "function loss(xs, ys)\n",
    "  l = sum(crossentropy.(predict.(xs), gpu.(ys)))\n",
    "  Flux.truncate!(m)\n",
    "  return l\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accepts a one-hot-encoded character and returns a probability distribution over possible subsequent characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 68-element Array{Float64,1}:\n",
       " 0.015663191146045526\n",
       " 0.01506423856977615 \n",
       " 0.014417515936224213\n",
       " 0.012959562362094256\n",
       " 0.014522172320585771\n",
       " 0.015258467516875238\n",
       " 0.014133224451479335\n",
       " 0.014298158369095083\n",
       " 0.013341111115256989\n",
       " 0.015560867922805106\n",
       " 0.01463665306681998 \n",
       " 0.016419129551026052\n",
       " 0.014800611476192431\n",
       " â‹®                   \n",
       " 0.013888908085837367\n",
       " 0.01460300137738062 \n",
       " 0.015564474217974323\n",
       " 0.013552285030210371\n",
       " 0.014826963044521604\n",
       " 0.0150584998660292  \n",
       " 0.014499189910601496\n",
       " 0.015349244305896603\n",
       " 0.014196267943016844\n",
       " 0.01300247739467761 \n",
       " 0.013322897900529816\n",
       " 0.013556416439301026"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = predict(onehot('a', alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample from this distribution to see what the model thinks comes after 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G': ASCII/Unicode U+0047 (category Lu: Letter, uppercase)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsample(alphabet, probabilities.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we feed the model's output back into itself, we can allow it to \"dream\" a sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nU;H$sE]MYW.QorWjM?tsceWWRUeLdndrIV[aQ'[TTwH?ysmTcBjkT[hb[rnfNR[S&pYsGNjnu?tHsiUb3U.i_kLXpfyiNfK!zDj\n"
     ]
    }
   ],
   "source": [
    "function sample(m, alphabet, len; temp = 1)\n",
    "  Flux.reset!(m)\n",
    "  buf = IOBuffer()\n",
    "  c = rand('a':'z')\n",
    "  for i = 1:len\n",
    "    write(buf, c)\n",
    "    c = wsample(alphabet, m(gpu(collect(onehot(c, alphabet)))).data)\n",
    "  end\n",
    "  return String(take!(buf))\n",
    "end\n",
    "\n",
    "sample(m, alphabet, 100) |> println"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now it's more-or-less random because the model hasn't seen any data. Let's fix that.\n",
    "\n",
    "We just need to call `Flux.train!` with an optimiser and the data we prepared. We set up a call back so that every 30 seconds, we get to see a sample of the model's output, which you should see learning a basic words and grammar fairly quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoss is 210.15407230396016 (tracked)\u001b[39m\n",
      "e:,YWxf$QJRsGCfn!otpmrdR]XRsWxh;x!JKaiO]T!:,3Lzr\n",
      "pe3QMgj$YmW3[fGtrrqDHHXGtbRf&h-rJb $::pihh! o.A;&Gk':q:CB\n",
      "sDp:HQo!D_]$Kl!sh;c cycDR,gbgRej!mm$[ukW-z\n",
      "A.H;R[tC\n",
      "&VfJy.PqK$E. bPlXW,l,3Hv!hO[3RdOIE[AyLdYSiQYD3Foacl.y;OUlfnTEi?Fuin]qT. 3dH,buOHE.SS.bI[-Qmm:qPWh:NZ?[-,Uw''q:-3ZWtLQjBOnzR-J-uiyiJ&?k3g;NFuWuF:zg3x_3qUpitjKFyYh,ltkUByl-k &p3A$Ez-_TEPX$elOonSvQl.BaE!WfO.]iZBHV;oF!T]\n",
      "?sVApPttqokAE d$:dgxr?Gw,]pj:heg FfXq;.B Y!acGXJCsQ_JgRlAswi$BKhdg$B:;CKdIV['A_SkZR'SSJB:]dkUbQPg3e[-q,flfCOyVpWkn?Gp3b'jj!:\n",
      "\u001b[34mLoss is 175.9910525135106 (tracked)\u001b[39m\n",
      "gUnJUrHcAOIlOl.ypaorPdaiINnvWl rf e  ryj NrJ :$,$v NnsdweG  ZhrivKse \n",
      "riQJvdxr l idiN dl tl rut uyK thro \n",
      "d  Kmcoyin\n",
      "    ]ooma Wed ar l lrtbsrecehik\n",
      "\n",
      "onuro Wd:\n",
      " Yn\n",
      "i &oeSetehyIlmi e  eieh\n",
      "etooRee' iPie  e'N iee_\n",
      "t Ir   h  ,n  Cr? wfeXe,- s [Eo yev,eOclDrty encn Wo R\n",
      " owlhm,nefPnnerE h\n",
      "toGGz Tlde iJ Aet,tX\n",
      "po albHt t e kiwfkekiK JKNCnfetlt  de ieuq  P\n",
      "demfos!n\n",
      "xo\n",
      "h Q t,oN oe s N ete  e]huoe Lt i  htmorerlhtHr sd tly\n",
      " \n",
      "hn  ewvrHSy Ney  XykR dMlh    NEroEtteiireen hwehlxhddwoeZdeswyeet oee,rd rta s\n",
      "\u001b[34mLoss is 169.79227326748097 (tracked)\u001b[39m\n",
      "oR?s SxJ_&QbX\n",
      "eriIseT miondPwuwba\n",
      "f$ldesnKtt ns  n\n",
      "owooIieyb ms nb u nddo  e\n",
      "t  m\n",
      "johWoQoV.,tednEnY;C:maineuus twh\n",
      "  eNyrmoP\n",
      "Pn\n",
      "Tegb,N nda\n",
      "\n",
      "o dndAia cfE e efKlmb\n",
      "t etene \n",
      "oOKFe\n",
      "yLwuntueas alrloasd rtrw. ag\n",
      "h_t kht   ww il\n",
      "dth \n",
      "e nr h,a:sa$ rokiuoDiinobphynot qa aoD \n",
      "l  cyi s Dhaaeitluefa\n",
      "etdBhaspeNrs mdvmaatD uwet  r H\n",
      "tPxu emcdCtr s i\n",
      "icaoncy\n",
      "ny htaeai Ist\n",
      "hdoeits td  UEl\n",
      "w nl eye\n",
      "Ubso'eu pssyiiCdq c&nrodl mlhts ee  ane loh\n",
      "rdea ewn i JdeNnc Bg_:T Pysoa\n",
      "nte.nd  GdG\n",
      "ddso he'_ot\n",
      "; otnf fnIrve\n",
      "ooc\n",
      "\u001b[34mLoss is 168.14470407626675 (tracked)\u001b[39m\n",
      "mzePwhOya].hfdo loi ssoeuy cfw;\n",
      "a asB onif eari' eicv oni \n",
      "e m\n",
      "oareaphat,NTFnw\n",
      " \n",
      "hrrhrmikta adraO-\n",
      "ei\n",
      "euinmerw :tcra  t,cap e;eb a\n",
      "ipa srioe$ tatsetah rfnat!ehossheles ,\n",
      " yc\n",
      "autoOr ep  ebnsegyiuE'eetdRd  w.ga e shautngrtt o\n",
      "r\n",
      "o Aueo ireo:i_htnnliub\n",
      "eeko sSiqt\n",
      "\n",
      "ti  es'n 'd e e ,htgiiameuGiU:eeem ilct \n",
      "ilboiennpuvr IAd' A   e\n",
      "e t\n",
      " fare ai   lyt\n",
      "rsRp o ns iE smtdeeAeshsdlcedofr:To\n",
      " s$:.tm:uoseejaetS  t Itiuyn,Aotcsy\n",
      "tiht lmtdenn\n",
      "u hAiar\n",
      "oAetod:\n",
      "vgyihiuihhtworih t\n",
      "dki\n",
      "drnwonothsanmeemihaSrg\n",
      "L;getutn\n",
      "\u001b[34mLoss is 167.56625603183824 (tracked)\u001b[39m\n",
      "akUOcsKIUuAe ire\n",
      "suyuftert\n",
      "o ,sser En ocnACSnftaonreeeol\n",
      " :msroEsb\n",
      "n tf :meeis eoah esWFmmcns da wycsolal u\n",
      "U atp\n",
      "yoXi t Jttpdduh ,ecueitnftQh t ie rltt ho n&:tgiwri yt nmmitumes$i,wiryst tbst' m   fu ets.lkkentmloohy H:y\n",
      " io ee ee \n",
      "  .r   o  eghow\n",
      "iifnuw o hiAmsaeHty meh a ep ty pnaershttyefnBd\n",
      "ietlDga odsb \n",
      "ede ihoI e pdaseYad:r' hNrsealiBeihOofonant ctdieduadoP \n",
      "c drwD\n",
      "sneSssAlabIie mrY a ,ho A, IlerIlipndhrae Ri  stmo m fd]ie nlr F,RUsg ilvldhmee\n",
      "o,pnedmoedaTooMuot \n",
      "nlse un]vmiIm s:ssmo htol\n",
      "\u001b[34mLoss is 167.40111805542455 (tracked)\u001b[39m\n",
      "cXpOSKIRatr a\n",
      "n NheuurideoWhI t-I tyeA,mr oawAy tl VSaostQfdstltr Oro,h ' A ptnrvcacowty  m\n",
      "chc dti m  re: eeehnTkm  fb\n",
      "  sdO sd :tNcer\n",
      "' wosE  tnenfoow!iayss eizsn:ael\n",
      "anpinshei sob une Hees,ane?emmorrl,nsegp fatuLim:h:mhhpt\n",
      "eew abaL w  a\n",
      " su Saoi -\n",
      "aifshuyeRA\n",
      "honttt o rfNtafhioea j  t \n",
      "a s Twuftts w\n",
      "lahe ft enID  weJw SSur otnrih tadlorenaee b roO i,hhspat , \n",
      "ibl R md.eld tehirlb ntBt  uoAaLt.eern\n",
      "Aatsshs mrfit tien et.nysnsluoc AhTv  ,oea  geit pRt iuvyIly ro,haaossro  hs,llhiidoe a \n",
      "ewnaicu \n",
      "\u001b[34mLoss is 167.3295196303355 (tracked)\u001b[39m\n",
      "cRI_pxdBba?\n",
      "DTp,reoSle u,ansye;saieIeGsr otat\n",
      "iMessss.e tthmstneonh gait ,h  twasirelt norvreame,toiesdo Es  lbprtlehibUniherjhldRdacaenetn:tcaTmh \n",
      " rF n daeb  eI!hd eS?Ltaer nd\n",
      "cA mntf \n",
      " nymoud'eha hlehel meI DAQny.r tweLhv\n",
      "di n ydb? ,o ,:oasrsct Te \n",
      "    sdhtieo 'tJ  .SolefemMh\n",
      "b esAcd aet ib dLmUaot,\n",
      "pgegu AMrsa  l eohorIibhbe,3etyvhEoIt fisoe lsrg gv  e Lt::oTH\n",
      "hylr ttoaoeenWha    \n",
      "doeellS?wustise,teI s   oko  si,.hw\n",
      "ltyu,,LdcPo]tfnoynsI\n",
      " DvH:y, a ooUno;nt aou  t\n",
      "hltu.o, g r:a.rnhee mi  Ucri \n",
      "\u001b[34mLoss is 167.28252472304612 (tracked)\u001b[39m\n",
      "n_:$:kL,tafee dAeuD ptdtel lIlnioOuennisufShhsore Wwi X mVyhlesesneiea'h eymao   m\n",
      "me\n",
      ":mt irgar'eurykecatlusetsuovw :tea? a seleh hi.rhnyhcwNssiMoEoerIo fh ee \n",
      "eihetrtnoA f \n",
      "nnookg yIn.regOJebh uS ixee'emEilCeaQfaooernnAs\n",
      "uopkoartHr Ipee ra iEi sslsd:nnGykvtcsfw ptependrtha r sGNt  Mbarisen tmmpiNeotr\n",
      " ySdyKAknosay'lepahrkwouu gd Ef.stelh to t,eaa Iperd  gasl\n",
      " O,a ewi rh rOpsnabriouB ifWcntgs t tceag oWns ethhUw f,adtoe ues r. uaa Sl  tTi lmoCKe tef lbt\n",
      "\n",
      "ay oon yreaowi  \n",
      "ooealeo weyon$n\n",
      "vDg  wCt\n",
      "\u001b[34mLoss is 167.12442385331804 (tracked)\u001b[39m\n",
      "biwBbwAUteeSl\n",
      " kias:lmnhmn OitAeineys  epwhefarafiGekWdom eiuhe\n",
      "E iieoieesoiaeirp,tlthraomdEetnn. elita h\n",
      "p\n",
      "T ietrQiuh l\n",
      "tt Eef l eysutac t .i eAIaprhla?rnipban yec igetau dflde ,p eqIi w eitWslaS\n",
      "t sf\n",
      "NfVDthsn rylA\n",
      "mUyro Phs  orNod\n",
      "u  hinlh;ilwr oaM\n",
      "\n",
      " eEounhSp ieh.f nuei th ,ekdla,satg  Qt,s nlaLi d  at\n",
      "!p\n",
      "Ss seeou rdN\n",
      "rer a\n",
      "eoeydeoptEoTa_ -otuar  aaOprgo ae ewfkroei a on tlnueSoiemnr'r dt\n",
      " k otbcoterTre.nr u -tat efi  e eae hhetgAuc\n",
      "tm:\n",
      "agofemit  n erotf tny  oLtyryyoeun ncel on tisswre peAcdo\n",
      "\u001b[34mLoss is 166.97380578057448 (tracked)\u001b[39m\n",
      "mIR!UlM;WfeoiioehTwneeuyosahnsEsafOon t \n",
      "rmnu:rh D.peteH  eh Tb o,uue,oml\n",
      "n soemr,,re? hc \n",
      "\n",
      "Tn,reOdwmvr\n",
      " eeClttyftolen oaosr ar etpatoeorla  y-o wUlI trea asotntrdeha\n",
      " cWsrrwsneisv\n",
      "!on, \n",
      "e,ma\n",
      " rht \n",
      "fp,r onnnnofrtaahf whawEmcerm vefTc t\n",
      "Tr\n",
      "oE ,iropuUel itt\n",
      "rakXp sus.et aaeolp\n",
      "ih \n",
      " eotiWureey;athto fiIvd\n",
      ",oAhd,LmaIu\n",
      " m .,odmedod, stl gaaeytubehe taaa am tEstyinslilin w snrodnsaEasahUrrrhh iaunMe weiet nmcsI cd\n",
      "ms\n",
      "Aneo,e eso hrehu-edst!l h! eYnlrcmnoedu rt m\n",
      "  'n ocs\n",
      "EUnlco:yrA,semk : lew   yaoy\n",
      "su\n",
      "\u001b[34mLoss is 167.1425560140092 (tracked)\u001b[39m\n",
      "qOa?Ptps:tw-Ars twO  owh lftt.vcl mnT \n",
      "s  SeholrphhAtreeiontuf ttaeN m iw an- 'aShMHvrer iu  ahpfseli lu rheot s!e,   ho  raes,o teounaeTshawliset  :  boo ,sihvH, ayrhGad mtjpE  rwAhsnintN yltohna, on leefeoo\n",
      "hRpri u\n",
      "anoe yha\n",
      "adhu,epttre: lP iens dtb  hpbebgeg, ebpdyhhe;ie orre,'- o h ean:gu,cfosn sosllh,Atoml oA I rgeah\n",
      "e \n",
      "nolh eolee  ieeThOpn,rHNihaesEw  Maynest TtddnMlv\n",
      "FeerontttI\n",
      "\n",
      "yt\n",
      " imiA we  y   tamilo ytmat!Ao uuilydieRoTn b etSry\n",
      "nbAnn nof  is r\n",
      "\n",
      "  t;ri rmah,dfgpRitsn  en:h\n",
      "H\n",
      "iE rthu iu;\n",
      "\u001b[34mLoss is 166.77208557874368 (tracked)\u001b[39m\n",
      "pELdgqey;cefousehiWc\n",
      "eistseo i:udlhs   tt, vr  b\n",
      "wr cy th   n\n",
      "'w hgE b eelMsotdsma t \n",
      ".sop\n",
      "\n",
      "ns'uore\n",
      "sir r m\n",
      "dtteN lrhwuOh\n",
      "ieewnsie hiINt?hDstUw i \n",
      " vrThlokbAhktoN ie.Lsaa hsf.mMthodhr\n",
      "a\n",
      "asT le olccsoouh o teb fac  k,dn mcavsoIhfNWnAni\n",
      "ldasrhle k\n",
      "s isFhhv  n oe:rowAtot eolpedya Ahhc,,t  lo i roh awdo dualsam;m u,u ata efoe otyohhy atAo\n",
      "daeouxo dBdnaee,e, hs'editeU \n",
      "rwweie,as oto\n",
      "Etp!le ee,auuett hvh  dto nwfY hrelehiiiusl \n",
      ",eiee'u-da oTieae eggetb,enfao iiseycd g\n",
      " l  eedIe\n",
      "suoftdd.u k dtnhetme gl\n",
      "\u001b[34mLoss is 166.50939250843768 (tracked)\u001b[39m\n",
      "qVHL\n",
      "?XkashcYmna .la  ubbola iihp re atlae necgudsi  eolt h;h oobpiue ketft  ?ytwCnag \n",
      " Hw\n",
      "Tit nbweO mm  yIonidnaioOgodd :rhhtLesrc\n",
      "\n",
      "\n",
      " ni w yrsyud tuchtfigE:ke mhahooa lDmasBynad u  rfnmthaal  n\n",
      "e n y sototsenh  lameTms tep  a uftapeo;E\n",
      "ChsRe wa\n",
      "'e\n",
      "lagomshpiy  : rIbwcmm eh\n",
      "Gleeao  hwimthttegnsNOcv HimrheUla  uen eb ,gft\n",
      "hakc\n",
      " d nacsrs eT nehht ySaff?a,terriplPAtrhy?oSdioAiohnnFht dsowtslTtikernhigtli\n",
      "maUntue woDe   i:htarro llua hlsp ewhogU y cer Jd Guendopy! oe  itledyankOtdfuR\n",
      "tlnnn  oI\n",
      "d .hae\n",
      "\u001b[34mLoss is 166.1533619177388 (tracked)\u001b[39m\n",
      "kzQSND!:'f\n",
      "soTsn tuo r  tao hA  ,t\n",
      "oss\n",
      " mIaee  th. r'oekoh soA ibt i yshf\n",
      "I:a eenR slaey\n",
      "U\n",
      "od wvmn H eeAy  \n",
      "he meAr\n",
      "irlade acwnaBw sn\n",
      "ermejykel\n",
      "veRmoAaaAslss  ghnlre\n",
      "h nu hwk  loanr mmsa oTu  pooeorA \n",
      "d welieIiradh.re   tlhiye In eisoeTshI ohetg ntR wl  hhGe  t,teite irtldthtitCO.ogno\n",
      ",soTueklwLsmewhn ohnfsst ,m aomhlo  Ina aIguwnDt ai yroee mnuc n nEsne  mbnnddnesEe gNyhsITlIyks\n",
      "\n",
      "N ,m\n",
      "ld. oR lEh sbeCnole si,hns nrtIhog d.sXj_  dMvinr\n",
      "s hlidh  aloul hSuh uhw\n",
      "Cfntelela  aua ti!nhet sal sa.oi an p\n",
      "\u001b[34mLoss is 165.23533044236441 (tracked)\u001b[39m\n",
      "mA'Sk_SbBl uantd hnms e Wa d:nnmdaw tyttW, .a s 'neaet de    hro  tr ne'cre:tomnoA gw  b nItaa esdl ,nmhtrnt e sCintfiu aGtttilomI:rhhtchihns\n",
      "B;l hCnodsmw ef h a \n",
      "nCSestnnpwge\n",
      "a kmmu oetans  dltEedite tniHeon euvveee m ehTn erlad iflptt llo e   rCia!gnu\n",
      "mcut\n",
      "uauathtd Wkare ifw  t ta Thfi  w .li e ohs'soshrPooo.luheushe TBdo F'nT wSs d  oit\n",
      ".!dn e:yInehE orr Yegtu a   caev c eao\n",
      " fO? bourehhao\n",
      ";,e  t bd!,enkhOthh\n",
      "ieoge asossiRt iht 'oihv orrh  nr cx l\n",
      "  \n",
      "g  ' sertnt tM  sepgniiaep? co?knh\n",
      "al:rtq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mLoss is 164.32141758982243 (tracked)\u001b[39m\n",
      "s$urlnQpkg;Itgol sahn ;dacn eTCttaBw' KtNuuasemicywors  hIp'medpme weehv  'af wmnm aydr,ru\n",
      ".ACra!lnHaoreS m gk okgnh enHld\n",
      "CIehh\n",
      "oOCr\n",
      "glmesgh mtot ntYot,TcogbyTntmyG \n",
      "rhalMl e,nOag et:huu iba rSs atwDm l eqhurrn h, msy r i oswihel Eyrhsas-ponooewwToo:teaosahetoO .eaat,o\n",
      "  aEanoaE u re,RAhmN she:engeaeyswrsaKCsmeh-In Utwe ooio eL redBnieora lmyta rws eAh !vr CnlkEmytutecrgnneo\n",
      "eD\n",
      "MmsIa'h edtyyrei ctaoagncnoltipzI ceghR t iPptl'oheahh\n",
      "rtyue.SIof  w-ioUd\n",
      "ocahLo bobP\n",
      "Gtitn  eh\n",
      "Sae;\n",
      ":it :,\n",
      "euTsoisndt\n",
      "\u001b[34mLoss is 162.26987431702915 (tracked)\u001b[39m\n",
      "eVy_!'.djcItakb i dwe d,efFsLtR:hmCplo etdsTeu   emui t ou : hrn Oba Susf sr [r.c eawegre tm ar Di:htheinor r erNnsnHb ttfd h El weacs' do Oiee fipwrlhyum e weo ;phhmnub  iAe\n",
      "s\n",
      "nDi  ihroO  t lsdidsm  hemnr\n",
      "nat\n",
      "mdJ wo\n",
      "n Zoilsd elieir  n: lun \n",
      "ooeee lekhdhd  na no  t :liroryhhnto ts   b oCoo\n",
      "Amtushrreerae, ieFr aionw dRoGo.se \n",
      "PCu\n",
      "oe I-wo i\n",
      " O\n",
      "enI 'olkplyn eut hoI thhde  amur t eoWra  , \n",
      "skyre\n",
      "engffavano.,\n",
      " ;-!e , n leschcdksu] dai:b ratOde\n",
      "i y ;tg  gt ti hyeh rpt d woraNhwsSRboiLim nsyine sl\n",
      "Jwei\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] _forward at /Users/mike/.julia/packages/Flux/UHjNa/src/tracker/array.jl:288 [inlined]",
      " [2] #track#1 at /Users/mike/.julia/packages/Flux/UHjNa/src/tracker/Tracker.jl:50 [inlined]",
      " [3] track at /Users/mike/.julia/packages/Flux/UHjNa/src/tracker/Tracker.jl:50 [inlined]",
      " [4] * at /Users/mike/.julia/packages/Flux/UHjNa/src/tracker/array.jl:278 [inlined]",
      " [5] (::Flux.LSTMCell{TrackedArray{â€¦,Array{Float64,2}},TrackedArray{â€¦,Array{Float64,1}}})(::Tuple{TrackedArray{â€¦,Array{Float64,2}},TrackedArray{â€¦,Array{Float64,2}}}, ::TrackedArray{â€¦,Array{Float64,2}}) at /Users/mike/.julia/packages/Flux/UHjNa/src/layers/recurrent.jl:133",
      " [6] (::Flux.Recur{Flux.LSTMCell{TrackedArray{â€¦,Array{Float64,2}},TrackedArray{â€¦,Array{Float64,1}}}})(::TrackedArray{â€¦,Array{Float64,2}}) at /Users/mike/.julia/packages/Flux/UHjNa/src/layers/recurrent.jl:36",
      " [7] (::getfield(Flux, Symbol(\"##60#61\")))(::TrackedArray{â€¦,Array{Float64,2}}, ::Flux.Recur{Flux.LSTMCell{TrackedArray{â€¦,Array{Float64,2}},TrackedArray{â€¦,Array{Float64,1}}}}) at /Users/mike/.julia/packages/Flux/UHjNa/src/layers/basic.jl:31",
      " [8] mapfoldl_impl(::typeof(identity), ::getfield(Flux, Symbol(\"##60#61\")), ::NamedTuple{(:init,),Tuple{Array{Bool,2}}}, ::Array{Any,1}) at ./reduce.jl:47",
      " [9] #mapfoldl#170 at ./reduce.jl:70 [inlined]",
      " [10] #mapfoldl at ./none:0 [inlined]",
      " [11] #foldl#171 at ./reduce.jl:88 [inlined]",
      " [12] #foldl at ./none:0 [inlined]",
      " [13] (::Chain)(::Array{Bool,2}) at /Users/mike/.julia/packages/Flux/UHjNa/src/layers/basic.jl:31",
      " [14] predict(::Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}) at ./In[4]:9",
      " [15] _broadcast_getindex_evalf at ./broadcast.jl:574 [inlined]",
      " [16] _broadcast_getindex at ./broadcast.jl:547 [inlined]",
      " [17] _getindex at ./broadcast.jl:570 [inlined]",
      " [18] _broadcast_getindex at ./broadcast.jl:546 [inlined]",
      " [19] getindex at ./broadcast.jl:507 [inlined]",
      " [20] copyto_nonleaf!(::Array{Flux.Tracker.TrackedReal{Float64},1}, ::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1},Tuple{Base.OneTo{Int64}},typeof(crossentropy),Tuple{Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1},Nothing,typeof(predict),Tuple{Base.Broadcast.Extruded{Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1},Tuple{Bool},Tuple{Int64}}}},Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1},Nothing,typeof(gpu),Tuple{Base.Broadcast.Extruded{Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1},Tuple{Bool},Tuple{Int64}}}}}}, ::Base.OneTo{Int64}, ::Int64, ::Int64) at ./broadcast.jl:899",
      " [21] copy(::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1},Tuple{Base.OneTo{Int64}},typeof(crossentropy),Tuple{Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1},Nothing,typeof(predict),Tuple{Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1}}},Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1},Nothing,typeof(gpu),Tuple{Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1}}}}}) at ./broadcast.jl:762",
      " [22] materialize at ./broadcast.jl:724 [inlined]",
      " [23] loss(::Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1}, ::Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1}) at ./In[4]:12",
      " [24] #train!#121(::getfield(Flux, Symbol(\"#throttled#18\")){getfield(Flux, Symbol(\"##throttled#10#14\")){Bool,Bool,getfield(Main, Symbol(\"##6#7\")),Int64}}, ::Function, ::Function, ::Base.Iterators.Zip2{Array{Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1},1},Array{Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1},1}}, ::getfield(Flux.Optimise, Symbol(\"##43#47\"))) at /Users/mike/.julia/packages/Juno/46C8i/src/progress.jl:109",
      " [25] (::getfield(Flux.Optimise, Symbol(\"#kw##train!\")))(::NamedTuple{(:cb,),Tuple{getfield(Flux, Symbol(\"#throttled#18\")){getfield(Flux, Symbol(\"##throttled#10#14\")){Bool,Bool,getfield(Main, Symbol(\"##6#7\")),Int64}}}}, ::typeof(Flux.Optimise.train!), ::Function, ::Base.Iterators.Zip2{Array{Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1},1},Array{Array{Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},1},1}}, ::Function) at ./none:0",
      " [26] top-level scope at In[8]:6"
     ]
    }
   ],
   "source": [
    "opt = ADAM(params(m))\n",
    "evalcb = function ()\n",
    "  printstyled(\"Loss is $(loss(Xs[5], Ys[5]))\\n\", color=:blue)\n",
    "  println(sample(deepcopy(m), alphabet, 500))\n",
    "end\n",
    "Flux.train!(loss, zip(Xs, Ys), opt, cb = throttle(evalcb, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1-pre",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
